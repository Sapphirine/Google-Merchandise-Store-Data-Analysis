{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6893-Final Project\n",
    "### -- Google Analytics Customer Revenue Prediction \n",
    "[dataset](https://www.kaggle.com/c/ga-customer-revenue-prediction/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 : Data Cleaning\n",
    "### 1) Sample Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our data is quite large (23.67GB), in order to explore our data more efficiently, we will sample data of 25,000 unique customers (using column 'fullVisitorId') for EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channelGrouping</th>\n",
       "      <th>customDimensions</th>\n",
       "      <th>date</th>\n",
       "      <th>device</th>\n",
       "      <th>fullVisitorId</th>\n",
       "      <th>geoNetwork</th>\n",
       "      <th>hits</th>\n",
       "      <th>socialEngagementType</th>\n",
       "      <th>totals</th>\n",
       "      <th>trafficSource</th>\n",
       "      <th>visitId</th>\n",
       "      <th>visitNumber</th>\n",
       "      <th>visitStartTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Organic Search</td>\n",
       "      <td>[{'index': '4', 'value': 'EMEA'}]</td>\n",
       "      <td>20171016</td>\n",
       "      <td>{\"browser\": \"Firefox\", \"browserVersion\": \"not ...</td>\n",
       "      <td>3162355547410993243</td>\n",
       "      <td>{\"continent\": \"Europe\", \"subContinent\": \"Weste...</td>\n",
       "      <td>[{'hitNumber': '1', 'time': '0', 'hour': '17',...</td>\n",
       "      <td>Not Socially Engaged</td>\n",
       "      <td>{\"visits\": \"1\", \"hits\": \"1\", \"pageviews\": \"1\",...</td>\n",
       "      <td>{\"campaign\": \"(not set)\", \"source\": \"google\", ...</td>\n",
       "      <td>1508198450</td>\n",
       "      <td>1</td>\n",
       "      <td>1508198450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Referral</td>\n",
       "      <td>[{'index': '4', 'value': 'North America'}]</td>\n",
       "      <td>20171016</td>\n",
       "      <td>{\"browser\": \"Chrome\", \"browserVersion\": \"not a...</td>\n",
       "      <td>8934116514970143966</td>\n",
       "      <td>{\"continent\": \"Americas\", \"subContinent\": \"Nor...</td>\n",
       "      <td>[{'hitNumber': '1', 'time': '0', 'hour': '10',...</td>\n",
       "      <td>Not Socially Engaged</td>\n",
       "      <td>{\"visits\": \"1\", \"hits\": \"2\", \"pageviews\": \"2\",...</td>\n",
       "      <td>{\"referralPath\": \"/a/google.com/transportation...</td>\n",
       "      <td>1508176307</td>\n",
       "      <td>6</td>\n",
       "      <td>1508176307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channelGrouping                            customDimensions      date  \\\n",
       "0  Organic Search           [{'index': '4', 'value': 'EMEA'}]  20171016   \n",
       "1        Referral  [{'index': '4', 'value': 'North America'}]  20171016   \n",
       "\n",
       "                                              device        fullVisitorId  \\\n",
       "0  {\"browser\": \"Firefox\", \"browserVersion\": \"not ...  3162355547410993243   \n",
       "1  {\"browser\": \"Chrome\", \"browserVersion\": \"not a...  8934116514970143966   \n",
       "\n",
       "                                          geoNetwork  \\\n",
       "0  {\"continent\": \"Europe\", \"subContinent\": \"Weste...   \n",
       "1  {\"continent\": \"Americas\", \"subContinent\": \"Nor...   \n",
       "\n",
       "                                                hits  socialEngagementType  \\\n",
       "0  [{'hitNumber': '1', 'time': '0', 'hour': '17',...  Not Socially Engaged   \n",
       "1  [{'hitNumber': '1', 'time': '0', 'hour': '10',...  Not Socially Engaged   \n",
       "\n",
       "                                              totals  \\\n",
       "0  {\"visits\": \"1\", \"hits\": \"1\", \"pageviews\": \"1\",...   \n",
       "1  {\"visits\": \"1\", \"hits\": \"2\", \"pageviews\": \"2\",...   \n",
       "\n",
       "                                       trafficSource     visitId  visitNumber  \\\n",
       "0  {\"campaign\": \"(not set)\", \"source\": \"google\", ...  1508198450            1   \n",
       "1  {\"referralPath\": \"/a/google.com/transportation...  1508176307            6   \n",
       "\n",
       "   visitStartTime  \n",
       "0      1508198450  \n",
       "1      1508176307  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show = pd.read_csv('/home/xc2418/data/train_v2.csv', nrows = 2)\n",
    "show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resulting from our big data, we will split our training data into 9 pieces ('split -l 200000 data.csv'), sample them seperately, and concat them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data = pd.read_csv('/home/xc2418/data/splited/base_data', dtype = {'fullVisitorId': 'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample n = 10000 unique customers \n",
    "import random as rd\n",
    "rd.seed(1)\n",
    "\n",
    "n = 25000\n",
    "id_unique = base_data['fullVisitorId'].unique()\n",
    "id_unique_l = list(id_unique)\n",
    "index = rd.sample(id_unique_l, n)\n",
    "index = [str(i) for i in index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from base_data\n",
    "base_data['fullVisitorId'] = base_data['fullVisitorId'].astype('str')\n",
    "data_samp = base_data.loc[base_data['fullVisitorId'].isin(index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xc2418/ENTER/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# sample from other pieces\n",
    "df = data_samp\n",
    "for path in glob.glob('/home/xc2418/data/splited/x*'):\n",
    "    # read splited files\n",
    "    df_temp = pd.read_csv(path, header = None, dtype = {'fullVisitorId': 'str'})\n",
    "    # rename the columns\n",
    "    df_temp.columns = data_samp.columns\n",
    "    # sample\n",
    "    df_temp['fullVisitorId'] = df_temp['fullVisitorId'].astype('str')\n",
    "    df_samp = df_temp.loc[df_temp['fullVisitorId'].isin(index)]\n",
    "    # append the sampled dataframe to the previous dataframe\n",
    "    df = pd.concat([df, df_samp], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get the sampled data of 25,000 unique customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write sampled data\n",
    "df.to_csv(\"/home/xc2418/data/sampled_data.csv\", header = True, index = False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Flatten data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we can see that there are multiple columns containing JSON blobs of varying depth. Then we are going to flatten these JSON columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import json\n",
    "import pandas.io.json as pdjson\n",
    "import ast\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(path):\n",
    "\n",
    "    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "\n",
    "    df = pd.read_csv(path, \n",
    "                     converters = {column: json.loads for column in JSON_COLUMNS}, \n",
    "                     dtype = {'fullVisitorId': 'str'})\n",
    "       \n",
    "    df['hits'] = df['hits'].apply(ast.literal_eval)\n",
    "    df['hits'] = df['hits'].str[0]\n",
    "    df['hits'] = df['hits'].apply(lambda x: {'index':np.NaN,'value':np.NaN} if pd.isnull(x) else x)\n",
    "    \n",
    "    df['customDimensions'] = df['customDimensions'].apply(ast.literal_eval)\n",
    "    df['customDimensions'] = df['customDimensions'].str[0]\n",
    "    df['customDimensions'] = df['customDimensions'].apply(lambda x: {'index':np.NaN,'value':np.NaN} if pd.isnull(x) else x)\n",
    "    \n",
    "    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource','hits','customDimensions']\n",
    "\n",
    "    for column in JSON_COLUMNS:\n",
    "        column_as_df = pdjson.json_normalize(df[column])\n",
    "        column_as_df.columns = [f\"{column}_{subcolumn}\" for subcolumn in column_as_df.columns]\n",
    "        df = df.drop(column, axis = 1).merge(column_as_df, right_index = True, left_index = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flat = flatten('/home/xc2418/data/sampled_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still some columns in JSON format: (they are in form of list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hits_customDimensions', 'hits_customMetrics', 'hits_customVariables', 'hits_experiment', 'hits_product', 'hits_promotion', 'hits_publisher_infos']\n"
     ]
    }
   ],
   "source": [
    "json_list = []\n",
    "\n",
    "# for each column\n",
    "for i in range(len(df_flat.columns)): \n",
    "    # see if some element 1 is a list\n",
    "    if (isinstance(df_flat.iloc[1,i], list)): \n",
    "        # save the list name to json_list\n",
    "        json_list.append(df_flat.columns[i])   \n",
    "        \n",
    "print(json_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Reduce Meaningless Features\n",
    "#### (1) Reduce Meaningless JSON Columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how many unique values the remaining JSON columns have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits_customDimensions has 2 unique values.\n",
      "hits_customMetrics has 2 unique values.\n",
      "hits_customVariables has 2 unique values.\n",
      "hits_experiment has 2 unique values.\n",
      "hits_product has 2388 unique values.\n",
      "hits_promotion has 17 unique values.\n",
      "hits_publisher_infos has 2 unique values.\n"
     ]
    }
   ],
   "source": [
    "for col in json_list:\n",
    "    coll = df_flat[col].astype('str')\n",
    "    n = coll.nunique(dropna = False)\n",
    "    print('%s has %d unique values.' %(col, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we take a look at what do their unique values look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### hits_customDimensions unique values: ['[]' 'nan']\n",
      "### hits_customMetrics unique values: ['[]' 'nan']\n",
      "### hits_customVariables unique values: ['[]' 'nan']\n",
      "### hits_experiment unique values: ['[]' 'nan']\n",
      "### hits_product looks like: [{'productSKU': 'GGOEYFKQ020699', 'v2ProductName': 'YouTube Custom Decals', 'v2ProductCategory': 'Home/Shop by Brand/YouTube/', 'productVariant': '(not set)', 'productBrand': '(not set)', 'productPrice': '1990000', 'localProductPrice': '1990000', 'isImpression': True, 'customDimensions': [], 'customMetrics': [], 'productListName': 'Category', 'productListPosition': '1'}, {'productSKU': 'GGOEYDHJ056099', 'v2ProductName': '22 oz YouTube Bottle Infuser', 'v2ProductCategory': 'Home/Shop by Brand/YouTube/', 'productVariant': '(not set)', 'productBrand': '(not set)', 'productPrice': '4990000', 'localProductPrice': '4990000', 'isImpression': True, 'customDimensions': [], 'customMetrics': [], 'productListName': 'Category', 'productListPosition': '2'}, {'productSKU': 'GGOEGAAX0351', 'v2ProductName': \"YouTube Men's Vintage Henley\", 'v2ProductCategory': 'Home/Shop by Brand/YouTube/', 'productVariant': '(not set)', 'productBrand': '(not set)', 'productPrice': '29990000', 'localProductPrice': '29990000', 'isImpression': True, 'customDimensions': [], 'customMetrics': [], 'productListName': 'Category', 'productListPosition': '3'}, {'productSKU': 'GGOEGAAX0356', 'v2ProductName': \"YouTube Men's Vintage Tank\", 'v2ProductCategory': 'Home/Shop by Brand/YouTube/', 'productVariant': '(not set)', 'productBrand': '(not set)', 'productPrice': '20990000', 'localProductPrice': '20990000', 'isImpression': True, 'customDimensions': [], 'customMetrics': [], 'productListName': 'Category', 'productListPosition': '4'}, {'productSKU': 'GGOEGAAX0284', 'v2ProductName': \"Women's YouTube Short Sleeve Hero Tee Black\", 'v2ProductCategory': 'Home/Shop by Brand/YouTube/', 'productVariant': '(not set)', 'productBrand': '(not set)', 'productPrice': '16990000', 'localProductPrice': '16990000', 'isImpression': True, 'customDimensions': [], 'customMetrics': [], 'productListName': 'Category', 'productListPosition': '5'}, {'productSKU': 'GGOEGAAX0317', 'v2ProductName': \"YouTube Men's Short Sleeve Hero Tee White\", 'v2ProductCategory': 'Home/Shop by Brand/YouTube/', 'productVariant': '(not set)', 'productBrand': '(not set)', 'productPrice': '16990000', 'localProductPrice': '16990000', 'isImpression': True, 'customDimensions': [], 'customMetrics': [], 'productListName': 'Category', 'productListPosition': '6'}, {'productSKU': 'GGOEGAAX0318', 'v2ProductName': \"YouTube Men's Short Sleeve Hero Tee Black\", 'v2ProductCategory': 'Home/Shop by Brand/YouTube/', 'productVariant': '(not set)', 'productBrand': '(not set)', 'productPrice': '16990000', 'localProductPrice': '16990000', 'isImpression': True, 'customDimensions': [], 'customMetrics': [], 'productListName': 'Category', 'productListPosition': '7'}, {'productSKU': 'GGOEGAAX0330', 'v2ProductName': \"YouTube Men's Long & Lean Tee Charcoal\", 'v2ProductCategory': 'Home/Shop by Brand/YouTube/', 'productVariant': '(not set)', 'productBrand': '(not set)', 'productPrice': '19990000', 'localProductPrice': '19990000', 'isImpression': True, 'customDimensions': [], 'customMetrics': [], 'productListName': 'Category', 'productListPosition': '8'}, {'productSKU': 'GGOEGAAX0290', 'v2ProductName': \"YouTube Women's Short Sleeve Hero Tee Charcoal\", 'v2ProductCategory': 'Home/Shop by Brand/YouTube/', 'productVariant': '(not set)', 'productBrand': '(not set)', 'productPrice': '18990000', 'localProductPrice': '18990000', 'isImpression': True, 'customDimensions': [], 'customMetrics': [], 'productListName': 'Category', 'productListPosition': '9'}, {'productSKU': 'GGOEGAAX0295', 'v2ProductName': \"YouTube Women's Short Sleeve Tri-blend Badge Tee Charcoal\", 'v2ProductCategory': 'Home/Shop by Brand/YouTube/', 'productVariant': '(not set)', 'productBrand': '(not set)', 'productPrice': '18990000', 'localProductPrice': '18990000', 'isImpression': True, 'customDimensions': [], 'customMetrics': [], 'productListName': 'Category', 'productListPosition': '10'}, {'productSKU': 'GGOEGAAX0732', 'v2ProductName': \"YouTube Women's Fleece Hoodie Black\", 'v2ProductCategory': 'Home/Shop by Brand/YouTube/', 'productVariant': '(not set)', 'productBrand': '(not set)', 'productPrice': '55990000', 'localProductPrice': '55990000', 'isImpression': True, 'customDimensions': [], 'customMetrics': [], 'productListName': 'Category', 'productListPosition': '11'}]\n",
      "### hits_promotion looks like: [{'promoId': 'Apparel Row 1', 'promoName': 'Apparel', 'promoCreative': 'home_main_link_apparel.jpg', 'promoPosition': 'Row 1'}, {'promoId': 'Backpacks Row 2 Combo', 'promoName': 'Backpacks', 'promoCreative': 'home_bags_google_2.jpg', 'promoPosition': 'Row 2 Combo'}, {'promoId': 'Mens T-Shirts Row 3-1', 'promoName': 'Mens T-Shirts', 'promoCreative': 'mens-tshirts.jpg', 'promoPosition': 'Row 3-1'}, {'promoId': 'Womens T-Shirts Row 3-2', 'promoName': 'Womens T-Shirts', 'promoCreative': 'womens-tshirts.jpg', 'promoPosition': 'Row 3-2'}, {'promoId': 'Office Row 5 Color Combo', 'promoName': 'Office', 'promoCreative': 'green_row_link_to_office.jpg', 'promoPosition': 'Row 5 Color Combo'}, {'promoId': 'Drinkware Row 4 Color Combo', 'promoName': 'Drinkware', 'promoCreative': 'red_row_hydrate.jpg', 'promoPosition': 'Row 4 Color Combo'}, {'promoId': 'Google Brand Row 7-1', 'promoName': 'Google Brand', 'promoCreative': 'home_lower_google_500.jpg', 'promoPosition': 'Brand Row 7-1'}, {'promoId': 'YouTube Brand Row 7-2', 'promoName': 'YouTube Brand', 'promoCreative': 'home_lower_youtube_500.jpg', 'promoPosition': 'Brand Row 7-2'}, {'promoId': 'Android Brand Row 7-3', 'promoName': 'Andriod Brand', 'promoCreative': 'home_lower_android_500.jpg', 'promoPosition': 'Brand Row 7-3'}]\n",
      "### hits_publisher_infos unique values: ['[]' 'nan']\n"
     ]
    }
   ],
   "source": [
    "for col in json_list:\n",
    "    coll = df_flat[col].astype('str')\n",
    "    n = coll.nunique(dropna = False)\n",
    "    if n == 2:\n",
    "        print('### %s unique values: %s' %(col, coll.unique()))\n",
    "    else:\n",
    "        print('### %s looks like: %s' %(col, coll.unique()[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the 5 JSON columns which has 2 unique values ('[  ]' and 'nan') don't provide any useful information, so we can drop them. <br>\n",
    "As for 'hits_product' and 'hits_promotion', they may provide few contributions to our result compared to the efforts we'll take to deal with them. So we will drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in json_list:\n",
    "    del(df_flat[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now our flattened dataset has 121 columns.\n"
     ]
    }
   ],
   "source": [
    "print('Now our flattened dataset has %s columns.' %df_flat.columns.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Reduce Constant Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a column has only 1 unique value, this column won't contribute to our final result, so we can drop this kind of column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_1 = []\n",
    "\n",
    "for col in df_flat.columns:\n",
    "    try:\n",
    "        n = df_flat[col].nunique(dropna = False) # including NAs\n",
    "        if n == 1: \n",
    "            value_1.append(col)\n",
    "            # if this column only contains 1 unique value, we delete it\n",
    "            del(df_flat[col])\n",
    "            \n",
    "    except TypeError:\n",
    "        coll = df_flat[col].astype('str')\n",
    "        n = coll.nunique(dropna = False)\n",
    "        if n == 1:\n",
    "            value_1.append(col)\n",
    "            del(df_flat[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns we have just deleted are ['socialEngagementType', 'device_browserSize', 'device_browserVersion', 'device_flashVersion', 'device_language', 'device_mobileDeviceBranding', 'device_mobileDeviceInfo', 'device_mobileDeviceMarketingName', 'device_mobileDeviceModel', 'device_mobileInputSelector', 'device_operatingSystemVersion', 'device_screenColors', 'device_screenResolution', 'geoNetwork_cityId', 'geoNetwork_latitude', 'geoNetwork_longitude', 'geoNetwork_networkLocation', 'totals_visits', 'trafficSource_adwordsClickInfo.criteriaParameters', 'hits_index', 'hits_value'], and our dataframe has 100 columns now.\n"
     ]
    }
   ],
   "source": [
    "print('The columns we have just deleted are %s, and our dataframe has %d columns now.' %(value_1, df_flat.columns.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Reduce Almost Constant Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some features, one single category may dominant (accounts for 95% or more). Then this feature is almost constant, and will contribute few to our prediction, so we'll drop this kind of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to find the max component for each column\n",
    "n = df_flat.shape[0]\n",
    "def max_freq(col, df = df_flat, n = n):\n",
    "    count = df[col].value_counts()\n",
    "    freq = count/n\n",
    "    return(max(freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trafficSource_campaign : 0.9420594005200967\n",
      "hits_appInfo.screenDepth : 0.9992928509512295\n",
      "hits_contentGroup.contentGroup1 : 0.9953465030338975\n",
      "hits_contentGroup.contentGroup3 : 0.9780099457092021\n",
      "hits_contentGroup.contentGroup4 : 0.9992928509512295\n",
      "hits_contentGroup.contentGroup5 : 0.9992928509512295\n",
      "hits_contentGroup.previousContentGroup1 : 0.9992928509512295\n",
      "hits_contentGroup.previousContentGroup2 : 0.9992928509512295\n",
      "hits_contentGroup.previousContentGroup3 : 0.9992928509512295\n",
      "hits_contentGroup.previousContentGroup4 : 0.9992928509512295\n",
      "hits_contentGroup.previousContentGroup5 : 0.9992928509512295\n",
      "hits_eCommerceAction.action_type : 0.9940462612345454\n",
      "hits_eCommerceAction.step : 0.9992016059126785\n",
      "hits_exceptionInfo.isFatal : 0.9992928509512295\n",
      "hits_hitNumber : 0.99023678087504\n",
      "hits_isEntrance : 0.9956886719284639\n",
      "hits_isInteraction : 0.9992928509512295\n",
      "hits_page.pagePathLevel4 : 0.9018659610383686\n",
      "hits_social.socialInteractionNetworkAction : 0.9992928509512295\n",
      "hits_time : 0.9992928509512295\n",
      "hits_type : 0.9956886719284639\n"
     ]
    }
   ],
   "source": [
    "# drop the column if the largest propotion is larger than 90%\n",
    "# print the columns we dropped\n",
    "for col in df_flat.columns:\n",
    "    if max_freq(col) > 0.9:\n",
    "        print(col,':',max_freq(col))\n",
    "        del(df_flat[col])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now our dataset has 79 columns\n"
     ]
    }
   ],
   "source": [
    "print('Now our dataset has %s columns' %df_flat.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) Drop Deprecated Fields\n",
    "According to the [Description of Dataset by Google](https://support.google.com/analytics/answer/3437719?hl=en), we will drop 2 deprecated fields: ['totals_totalTransactionRevenue', 'device_isMobile']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del[df_flat['totals_totalTransactionRevenue']]\n",
    "del[df_flat['device_isMobile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write cleaned data\n",
    "df_flat.to_csv(\"/home/xc2418/data/sampled_data_cleaned.csv\", header = True, index = False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Flatten and Clean the Whole Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name splited files except for the first one(has column names)\n",
    "col_name = pd.read_csv('/home/xc2418/final_proj/data/splited/xaa').columns\n",
    "\n",
    "path = '/home/xc2418/final_proj/data/splited'\n",
    "filenames = glob.glob(path + '/x*')\n",
    "\n",
    "for file in filenames:\n",
    "    spacename = file.split(\"/\")[-1]\n",
    "    # read splited files\n",
    "    data = pd.read_csv(file, header = None)\n",
    "    # rename the columns\n",
    "    data.columns = col_name\n",
    "    \n",
    "    data.to_csv('/home/xc2418/final_proj/data/splited/named/%s.csv' %spacename, \n",
    "                header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['hits_customDimensions', 'hits_customMetrics', 'hits_customVariables', \n",
    "       'hits_experiment', 'hits_product', 'hits_promotion', 'hits_publisher_infos',\n",
    "       'socialEngagementType', 'device_browserSize', 'device_browserVersion', \n",
    "       'device_flashVersion', 'device_language', 'device_mobileDeviceBranding', \n",
    "       'device_mobileDeviceInfo', 'device_mobileDeviceMarketingName', 'device_mobileDeviceModel', \n",
    "       'device_mobileInputSelector', 'device_operatingSystemVersion', 'device_screenColors', \n",
    "       'device_screenResolution', 'geoNetwork_cityId', 'geoNetwork_latitude', 'geoNetwork_longitude',\n",
    "       'geoNetwork_networkLocation', 'totals_visits', 'trafficSource_adwordsClickInfo.criteriaParameters', \n",
    "       'hits_index', 'hits_value', 'trafficSource_campaign', 'hits_appInfo.screenDepth', \n",
    "       'hits_contentGroup.contentGroup1', 'hits_contentGroup.contentGroup3', 'hits_contentGroup.contentGroup4',\n",
    "       'hits_contentGroup.contentGroup5', 'hits_contentGroup.previousContentGroup1', 'hits_contentGroup.previousContentGroup2', \n",
    "       'hits_contentGroup.previousContentGroup3', 'hits_contentGroup.previousContentGroup4',\n",
    "       'hits_contentGroup.previousContentGroup5', 'hits_eCommerceAction.action_type',\n",
    "       'hits_eCommerceAction.step', 'hits_exceptionInfo.isFatal', 'hits_hitNumber', 'hits_isEntrance',\n",
    "       'hits_isInteraction', 'hits_page.pagePathLevel4', 'hits_social.socialInteractionNetworkAction', \n",
    "       'hits_time hits_type', 'totals_totalTransactionRevenue', 'device_isMobile', 'hits_minute'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten splited files\n",
    "path = '/home/xc2418/final_proj/data/splited/named'\n",
    "filenames = glob.glob(path + '/*.csv')\n",
    "\n",
    "for file in filenames:\n",
    "    spacename = file.split(\"/\")[-1]\n",
    "    data = flatten(file)\n",
    "    # delete usless columns\n",
    "    for coll in col:\n",
    "        del(data[coll])\n",
    "    data.to_csv('/home/xc2418/final_proj/data/flattened/%s' %spacename,\n",
    "                header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all the files\n",
    "for file in glob.glob('/home/xc2418/final_proj/data/flattened/*'):\n",
    "    # skip the headers\n",
    "    data = pd.read_csv(file, skiprows = [0]) \n",
    "    data.to_csv('/home/xc2418/final_proj/data/flat_data.csv', mode = 'a+', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
